{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a5a33c2-1b84-4cf2-a3f2-a4db249faf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.dataset import *\n",
    "# from train import PapsClsModel\n",
    "import custom_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c14b07-3437-45d5-83fc-332423f9f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8207a6d3-0a45-4369-a96b-26e4c1acb1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv( '../lbp_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ca9ae36-b79d-4a60-8c8c-c52e31339d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16569, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea42013d-f860-40e9-84c8-65696489ab8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>file_name</th>\n",
       "      <th>task</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>occluded</th>\n",
       "      <th>des</th>\n",
       "      <th>cell_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1539, 199, 139, 211]</td>\n",
       "      <td>1539</td>\n",
       "      <td>199</td>\n",
       "      <td>139</td>\n",
       "      <td>211</td>\n",
       "      <td>C</td>\n",
       "      <td>Candida</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1337, 102, 256, 136]</td>\n",
       "      <td>1337</td>\n",
       "      <td>102</td>\n",
       "      <td>256</td>\n",
       "      <td>136</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[220, 619, 166, 169]</td>\n",
       "      <td>220</td>\n",
       "      <td>619</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[658, 1747, 191, 166]</td>\n",
       "      <td>658</td>\n",
       "      <td>1747</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>patch_images/2021.01.14/LBC424-20210111(1)/LBC...</td>\n",
       "      <td>[AS6] LBC424</td>\n",
       "      <td>[1571, 365, 136, 146]</td>\n",
       "      <td>1571</td>\n",
       "      <td>365</td>\n",
       "      <td>136</td>\n",
       "      <td>146</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASC-US</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ASC-US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          file_name          task  \\\n",
       "0   0  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "1   1  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "2   2  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "3   3  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "4   4  patch_images/2021.01.14/LBC424-20210111(1)/LBC...  [AS6] LBC424   \n",
       "\n",
       "                    bbox  xmin  ymin    w    h label label_id  occluded  des  \\\n",
       "0  [1539, 199, 139, 211]  1539   199  139  211     C  Candida         0  NaN   \n",
       "1  [1337, 102, 256, 136]  1337   102  256  136    AS   ASC-US         0  NaN   \n",
       "2   [220, 619, 166, 169]   220   619  166  169    AS   ASC-US         0  NaN   \n",
       "3  [658, 1747, 191, 166]   658  1747  191  166    AS   ASC-US         0  NaN   \n",
       "4  [1571, 365, 136, 146]  1571   365  136  146    AS   ASC-US         0  NaN   \n",
       "\n",
       "  cell_type  \n",
       "0    ASC-US  \n",
       "1    ASC-US  \n",
       "2    ASC-US  \n",
       "3    ASC-US  \n",
       "4    ASC-US  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7b4b687-6673-44fa-9cba-c49f0edb1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASC-US          8162\n",
       "LSIL            3821\n",
       "Negative        1773\n",
       "HSIL            1129\n",
       "ASC-H            989\n",
       "Candida          484\n",
       "Endocervical     209\n",
       "Carcinoma          1\n",
       "Endometrial        1\n",
       "Name: label_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33454f69-d737-443e-b782-ba6f9796e3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.label_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3589c66-04c5-40ca-bb43-45ce4c70f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PapsClsModel(LightningModule) :\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path : str,\n",
    "        arch: str = 'resnet18',\n",
    "        pretrained: bool = False,\n",
    "        lr: float = 0.9,\n",
    "        momentum: float = 0.9,\n",
    "        weight_decay: float = 1e-4,\n",
    "        batch_size: int =256,\n",
    "        workers: int = 16,\n",
    "        num_classes: int = 5,\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.arch = arch\n",
    "        self.pretrained = pretrained\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # if args.arch not in models.__dict__.keys() : \n",
    "            # self.models = EfficientNet.from_name(args.arch)  \n",
    "        if self.arch not in models.__dict__.keys() :\n",
    "            self.models = custom_models.__dict__[self.arch](pretrained=False, img_size=448)\n",
    "        else :\n",
    "            self.models = models.__dict__[self.arch](pretrained=self.pretrained)\n",
    "        # else :\n",
    "        #     print('only resnet is supported') \n",
    "        #     self.models = models.__dict__[self.arch](pretrained=self.pretrained) \n",
    "        \n",
    "        shape = self.models.fc.weight.shape\n",
    "        self.models.fc = nn.Linear(shape[1], self.num_classes)\n",
    "            \n",
    "        # print(\"=> creating model '{}'\".format(args.arch))\n",
    "        self.train_dataset: Optional[Dataset] = None\n",
    "        self.eval_dataset: Optional[Dataset] = None\n",
    "        self.train_acc1 = Accuracy(top_k=1)\n",
    "        self.eval_acc1 = Accuracy(top_k=1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.models(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx) :\n",
    "        images, targets = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        #update metric\n",
    "        self.train_acc1(outputs, targets)\n",
    "        self.log('train_acc', self.train_acc1, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def eval_step(self, batch, batch_idx, prefix: str) :\n",
    "        images, targets = batch\n",
    "        outputs = self(images)\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        self.log(f'{prefix}_loss', loss)\n",
    "        self.eval_acc1(outputs, targets)\n",
    "        self.log(f'{prefix}_acc1', self.eval_acc1, prog_bar=True)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx) :\n",
    "        return self.eval_step(batch, batch_idx, 'val')\n",
    "    \n",
    "    def test_setup(self, batch, batch_idx) :\n",
    "        return self.eval_step(batch, batch_idx, 'test')\n",
    "    \n",
    "    def configure_optimizers(self) :\n",
    "        optimizer = optim.SGD(self.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n",
    "        scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch : 0.1 **(epoch //30))\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5dd4157-16ae-46da-ad88-796fd5eab889",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PapsClsModel(\n",
    "    data_path='../lbp_data',\n",
    "    # arch='swin_t',\n",
    "    arch='resnet18',\n",
    "    pretrained=False,\n",
    "    workers=8,\n",
    "    lr = 0.01,\n",
    "    batch_size=32,\n",
    "    weight_decay=1e-4,\n",
    "    num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a27d133-522b-48ef-8b3d-20267b4219f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.parameters() :\n",
    "#     print(i.shape)\n",
    "# for i in model.models.parameters() :\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17092547-234f-4be8-b911-fadb15dfc2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "class PapsDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str = '../lbp_data/'):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.train_transform = train_transforms\n",
    "        self.test_transform = test_transforms\n",
    "\n",
    "        # self.dims is returned when you call dm.size()\n",
    "        # Setting default dims here because we know them.\n",
    "        # Could optionally be assigned dynamically in dm.setup()\n",
    "        self.dims = (1, 28, 28)\n",
    "        self.num_classes = 5\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_df = pd.read_csv(self.data_dir + 'train.csv')\n",
    "            self.train_dataset = PapsDataset(train_df, defaultpath=self.data_dir, transform=self.train_transforms)\n",
    "            test_df = pd.read_csv(self.data_dir + 'test.csv')\n",
    "            self.test_dataset = PapsDataset(test_df, defaultpath=self.data_dir, transform=self.test_transforms)            \n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_df = pd.read_csv(self.data_dir + 'test.csv')\n",
    "            self.test_dataset = PapsDataset(test_df, defaultpath=self.data_dir, transform=self.test_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2cd2d13-6b2c-44e6-8db1-e15de1a45c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:175: LightningDeprecationWarning: DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\"DataModule property `dims` was deprecated in v1.5 and will be removed in v1.7.\")\n"
     ]
    }
   ],
   "source": [
    "dm = PapsDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c5393b-e5f4-4a1c-9739-e6504300eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(dm.train_dataloader()))\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a017ec7-c1b5-4cf7-9418-5b63e59d6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:114: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:152: LightningDeprecationWarning: DataModule property `test_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15869, 13)\n",
      "(5801, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type     | Params\n",
      "----------------------------------------\n",
      "0 | models     | ResNet   | 11.2 M\n",
      "1 | train_acc1 | Accuracy | 0     \n",
      "2 | eval_acc1  | Accuracy | 0     \n",
      "----------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "22.358    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|â–         | 29/678 [01:18<29:21,  2.71s/it, loss=3.74, v_num=2, train_acc=0.250] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/deepspeed/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "img_size = 448\n",
    "\n",
    "trainer_defaults = dict(\n",
    "    # callbacks = [\n",
    "    #     # the PyTorch example refreshes every 10 batches\n",
    "    #     # TQDMProgressBar(refresh_rate=10),\n",
    "    #     # save when the validation top1 accuracy improves\n",
    "    #     ModelCheckpoint(monitor=\"val_acc1\", mode=\"max\"),\n",
    "    # ],    \n",
    "    # plugins = \"deepspeed_stage_2_offload\",\n",
    "    precision = 16,\n",
    "    max_epochs = 90,\n",
    "    accelerator = 'gpu', # auto, or select device, \"gpu\"\n",
    "    devices = 1, # number of gpus\n",
    "    logger = True,\n",
    "    benchmark = True,\n",
    "    # strategy = \"ddp\",\n",
    "    )\n",
    "\n",
    "model = PapsClsModel(\n",
    "    data_path='../lbp_data',\n",
    "    # arch='swin_t',\n",
    "    arch='resnet18',\n",
    "    pretrained=False,\n",
    "    workers=8,\n",
    "    lr = 0.01,\n",
    "    batch_size=32,\n",
    "    weight_decay=1e-4,\n",
    "    num_classes=5)\n",
    "\n",
    "trainer = Trainer(**trainer_defaults)\n",
    "trainer.fit(model, dm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dc6358-b23e-4dc8-88d8-8dd056430d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/beomgon/pytorch/LBP_scl/clf_from_roi/notebooks/lightning_logs/version_2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logger.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b14d66-9a73-4267-a19d-837948637d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1660cde-cace-4b2d-a827-de1b754d2958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590281ba-2c7b-4605-b141-06fef0e316d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed",
   "language": "python",
   "name": "deepspeed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
