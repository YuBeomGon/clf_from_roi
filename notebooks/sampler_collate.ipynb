{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5a33c2-1b84-4cf2-a3f2-a4db249faf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.scottcondron.com/jupyter/visualisation/audio/2020/12/02/dataloaders-samplers-collate.html\n",
    "# But what are PyTorch DataLoaders really\n",
    "\n",
    "#pytorch tutorial from raw\n",
    "# https://pytorch.org/tutorials/beginner/nn_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c14b07-3437-45d5-83fc-332423f9f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.dataset import *\n",
    "# from train import PapsClsModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0e473-bec9-4184-83bb-8ffdcbe84a1d",
   "metadata": {},
   "source": [
    "A quick refresher: PyTorch Datasets are just things that have a length and are indexable so that len(dataset) will work and dataset[index] will return a tuple of (x,y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60a20483-7449-48ec-8a89-65df35089dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs values:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "ys values:  [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "X = list(range(1, 11))\n",
    "Y = list(range(11,21))\n",
    "print('xs values: ', X)\n",
    "print('ys values: ', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e7acf1a-a1f8-463b-a674-14381cae8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(zip(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e63a8498-0987-44f3-82a9-68d0ae75edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zip(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07407289-4949-4932-9c9a-9a958416be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in zip(X, Y) :\n",
    "#     print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3549d0c-5b7b-4587-9afd-a2a1046507bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fef141e0-39ee-4054-b4a1-9642618a4125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b2a6f8-98ec-49cc-af29-bb9fd39d1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyDataset :\n",
    "    def __init__(self, X, Y) :\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    def __getitem__(self, i) :\n",
    "        return self.X[i], self.Y[i]\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ce4356c-4443-476e-aea7-6d3e98dee1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ToyDataset(X, Y)\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db0a2f2-28e1-4b34-8486-816d717df89c",
   "metadata": {},
   "source": [
    "The len() function will attempt to call a method named __len__() on the class,\n",
    "iterator like list, dictionary has built in magic len method, so len(list) is working\n",
    "for class, need to add __len__ method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cb264db-8b66-4b34-beaf-c1738a04698a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a4c24d-5bbf-4d69-b846-044914baaf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 6]) tensor([17, 16])\n",
      "tensor([4, 5]) tensor([14, 15])\n",
      "tensor([ 3, 10]) tensor([13, 20])\n",
      "tensor([1, 9]) tensor([11, 19])\n",
      "tensor([2, 8]) tensor([12, 18])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for x, y in DataLoader(dataset, batch_size=2, shuffle=True) :\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f863e",
   "metadata": {},
   "source": [
    "Every DataLoader has a Sampler which is used internally to get the indices for each batch. Each index is used to index into your Dataset to grab the data (x, y). You can ignore this for now, but DataLoaders also have a batch_sampler which returns the indices for each batch in a list if batch_size is greater than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912905be",
   "metadata": {},
   "source": [
    "\n",
    "SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e74da6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_sampler = DataLoader(dataset).sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d410b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in default_sampler :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5268308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.sampler.SequentialSampler"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d71c4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SequentialSampler\n",
    "sampler = SequentialSampler(dataset)\n",
    "\n",
    "for x in sampler :\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ab316",
   "metadata": {},
   "source": [
    "RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca81d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "5\n",
      "7\n",
      "8\n",
      "3\n",
      "4\n",
      "6\n",
      "9\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "random_sampler = DataLoader(dataset, shuffle=True).sampler\n",
    "\n",
    "for index in random_sampler :\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d01d3673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.sampler.RandomSampler"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(random_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fb728c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "9\n",
      "6\n",
      "5\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "random_sampler = RandomSampler(dataset)\n",
    "\n",
    "for x in random_sampler :\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0841cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "9\n",
      "4\n",
      "1\n",
      "0\n",
      "6\n",
      "8\n",
      "2\n",
      "5\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset, sampler=random_sampler)\n",
    "for i in dl.sampler :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1dc802",
   "metadata": {},
   "source": [
    "So we've seen that every DataLoader has a sampler internally which is either SequentialSampler or RandomSampler depending on the value of shuffle, and these are iterated over to get the indices of the Dataset to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0859ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "class HalvesSampler(Sampler) :\n",
    "    def __init__(self, dataset) :\n",
    "        self.half = int(len(dataset)/2)\n",
    "        self.first_indices = list(range(self.half))\n",
    "        self.sec_indices = list(range(self.half, len(dataset)))\n",
    "\n",
    "    def __iter__(self) :\n",
    "        #shuffle first half and second\n",
    "        random.shuffle(self.first_indices)\n",
    "        random.shuffle(self.sec_indices)\n",
    "        \n",
    "        #iter first half, then second half\n",
    "        return iter(self.first_indices + self.sec_indices)\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.first_indices) + len(self.sec_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1223c493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "my_sampler = HalvesSampler(dataset)\n",
    "print(my_sampler.first_indices)\n",
    "print(my_sampler.sec_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1df03e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "3\n",
      "6\n",
      "9\n",
      "8\n",
      "7\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in my_sampler :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0f47ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) tensor([11])\n",
      "tensor([4]) tensor([14])\n",
      "tensor([3]) tensor([13])\n",
      "tensor([5]) tensor([15])\n",
      "tensor([2]) tensor([12])\n",
      "tensor([10]) tensor([20])\n",
      "tensor([7]) tensor([17])\n",
      "tensor([9]) tensor([19])\n",
      "tensor([8]) tensor([18])\n",
      "tensor([6]) tensor([16])\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset, sampler=my_sampler)\n",
    "for x, y in dl:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd8af12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4,  5,  2,  3,  1,  7, 10]) tensor([14, 15, 12, 13, 11, 17, 20])\n",
      "tensor([8, 6, 9]) tensor([18, 16, 19])\n"
     ]
    }
   ],
   "source": [
    "batch_size=7\n",
    "dl = DataLoader(dataset, batch_size=batch_size, sampler=my_sampler)\n",
    "\n",
    "for x, y in dl:\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcce3a",
   "metadata": {},
   "source": [
    "BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab553dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0, 1, 2]\n",
      "1 [3, 4, 5]\n",
      "2 [6, 7, 8]\n",
      "3 [9]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "default_batch_sampler = DataLoader(dataset, batch_size=batch_size).batch_sampler\n",
    "for i, batch_indices in enumerate(default_batch_sampler) :\n",
    "    print(i, batch_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27a6dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.sampler.BatchSampler"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6dc7945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps another sampler to yield a mini-batch of indices.\n",
      "\n",
      "    Args:\n",
      "        sampler (Sampler or Iterable): Base sampler. Can be any iterable object\n",
      "        batch_size (int): Size of mini-batch.\n",
      "        drop_last (bool): If ``True``, the sampler will drop the last batch if\n",
      "            its size would be less than ``batch_size``\n",
      "\n",
      "    Example:\n",
      "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n",
      "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n",
      "        >>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n",
      "        [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "print(BatchSampler.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02a90741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 0]\n",
      "1 [3, 2]\n",
      "2 [4, 8]\n",
      "3 [7, 6]\n",
      "4 [5, 9]\n"
     ]
    }
   ],
   "source": [
    "batch_sampler = BatchSampler(my_sampler, batch_size=2, drop_last=False)\n",
    "for i, batch_indices in enumerate(batch_sampler) :\n",
    "    print(i, batch_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df74d26",
   "metadata": {},
   "source": [
    "Custom Batch Sampler\n",
    "Similar to a custom sampler, you can also create a batch_sampler. Why? If for some reason you wanted to only batch certain things together (like only if they're the same length), or if you wanted to show some examples more often than others, a custom BatchSampler is great for this.\n",
    "\n",
    "To create a custom batch_sampler, we just do the same as we did with a custom Sampler but our iterator returns batches of indices, rather than individual indices.\n",
    "\n",
    "Let's create a BatchSampler which only batches together values from the first half of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf2140",
   "metadata": {},
   "source": [
    "baatch sampler considering aspect ratio or area,  or class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "882d76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(indices, chunk_size):\n",
    "    return torch.split(torch.tensor(indices), chunk_size)\n",
    "\n",
    "class EachHalfTogetherBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        halfway_point = len(dataset) // 2 \n",
    "        self.first_half_indices = list(range(halfway_point))\n",
    "        self.second_half_indices = list(range(halfway_point, len(dataset)))\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.first_half_indices)\n",
    "        random.shuffle(self.second_half_indices)\n",
    "        first_half_batches  = chunk(self.first_half_indices, self.batch_size)\n",
    "        second_half_batches = chunk(self.second_half_indices, self.batch_size)\n",
    "        combined = list(first_half_batches + second_half_batches)\n",
    "        combined = [batch.tolist() for batch in combined]\n",
    "        random.shuffle(combined)\n",
    "        return iter(combined)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.first_half_indices) + len(self.second_half_indices)) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e03270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7]\n",
      "[8, 6]\n",
      "[0]\n",
      "[2, 4]\n",
      "[5]\n",
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "each_half_together_batch_sampler = EachHalfTogetherBatchSampler(dataset, batch_size)\n",
    "for x in each_half_together_batch_sampler:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a03a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch #0. x0: tensor([8, 6])\n",
      "          y0: tensor([18, 16])\n",
      "Batch #1. x1: tensor([1])\n",
      "          y1: tensor([11])\n",
      "Batch #2. x2: tensor([10])\n",
      "          y2: tensor([20])\n",
      "Batch #3. x3: tensor([4, 3])\n",
      "          y3: tensor([14, 13])\n",
      "Batch #4. x4: tensor([2, 5])\n",
      "          y4: tensor([12, 15])\n",
      "Batch #5. x5: tensor([7, 9])\n",
      "          y5: tensor([17, 19])\n"
     ]
    }
   ],
   "source": [
    "for i, (xb,yb) in enumerate(DataLoader(dataset, batch_sampler=each_half_together_batch_sampler)):\n",
    "    print(f'Batch #{i}. x{i}:', xb)\n",
    "    print(f'          y{i}:', yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeebc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fe810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9535516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ecfdee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
